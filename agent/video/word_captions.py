
"""
Word-Level Caption System - Modern TikTok/YouTube Shorts style captions
"""

import os
import logging
import subprocess
import sys
import re
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from agent.utils import run_command as _run_command_original

# Cache for detected FFmpeg filters (populated on first use)
_FFMPEG_FILTERS = None

def _ffmpeg_supports_filter(filter_name: str) -> bool:
    """Check if the local FFmpeg binary supports a given filter.

    This helper executes ``ffmpeg -v quiet -filters`` exactly once per
    interpreter session, caches the list of available filters and re-uses it
    for subsequent calls.

    Args:
        filter_name: The FFmpeg filter name to look for (case-sensitive, the
            canonical name as shown by ``ffmpeg -filters``).

    Returns:
        True if the filter is present in the local FFmpeg build, otherwise
        False.
    """
    global _FFMPEG_FILTERS

    if _FFMPEG_FILTERS is None:
        logging.debug("Querying FFmpeg for supported filters …")
        success, stdout, stderr = run_command(["ffmpeg", "-v", "quiet", "-filters"])
        if not success:
            # Log the error only once and assume no filters are available.
            logging.warning(f"Could not obtain FFmpeg filter list: {stderr}")
            _FFMPEG_FILTERS = set()
        else:
            filters = set()
            for line in stdout.splitlines():
                # Each usable line starts with flags followed by the filter name.
                # Example: " T.C hflip            V->V       ..." -> 'hflip'
                match = re.match(r"^\s*[A-Z\.]{2,}\s+([a-zA-Z0-9_]+)\s", line)
                if match:
                    filters.add(match.group(1))
            _FFMPEG_FILTERS = filters
            logging.debug(f"Detected {len(_FFMPEG_FILTERS)} FFmpeg filters")

    supported = filter_name in _FFMPEG_FILTERS
    logging.debug(f"FFmpeg filter '{filter_name}' supported: {supported}")
    return supported


def _sanitize_path_for_ffmpeg_filter(path: str) -> str:
    """
    Prepares a path for use in an FFmpeg filter graph on Windows.
    - Converts backslashes to forward slashes 
    - Properly escapes the colon and backslashes for FFmpeg filter syntax
    """
    if sys.platform == "win32":
        # Convert to forward slashes first
        path = path.replace('\\', '/')
        # Escape the colon after the drive letter for FFmpeg filter syntax
        if ':' in path and len(path) > 2 and path[1] == ':':
            # For Windows paths like C:/path, escape as C\\:/path  
            path = path.replace(':', '\\:')
    return path

from agent.video.ffmpeg_utils import prepend_ffmpeg_path

# Absolute directory of the full-featured FFmpeg build (gyan.dev)
_FULL_FFMPEG_DIR = r"C:\Users\hweizen\AppData\Local\Microsoft\WinGet\Packages\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\ffmpeg-7.1.1-full_build\bin"

# Override run_command to use full FFmpeg
def run_command(cmd):
    """Override run_command to force use of full FFmpeg build."""
    if isinstance(cmd, list) and len(cmd) > 0:
        # Replace 'ffmpeg' and 'ffprobe' commands with full path
        if cmd[0] == 'ffmpeg':
            cmd[0] = os.path.join(_FULL_FFMPEG_DIR, 'ffmpeg.exe')
            logging.debug(f"Replaced ffmpeg with: {cmd[0]}")
        elif cmd[0] == 'ffprobe':
            cmd[0] = os.path.join(_FULL_FFMPEG_DIR, 'ffprobe.exe')
            logging.debug(f"Replaced ffprobe with: {cmd[0]}")
    return _run_command_original(cmd)

def add_word_captions(video_path: str, transcript_data: dict, output_path: str) -> str:
    """
    Add modern word-by-word captions to a video using pre-existing transcript
    data. The function prefers the FFmpeg *drawtext* filter for maximum
    Windows compatibility but will automatically fall back to the *subtitles*
    filter if *drawtext* is unavailable or fails at runtime.

    Args:
        video_path:     Path to the input video file.
        transcript_data: Word-level timestamp data generated by the timing
                         extraction step.
        output_path:    Desired path of the captioned output video.

    Returns:
        The ``output_path`` once captioning finished successfully.
    """
    try:
        # Log initial FFmpeg location
        import subprocess
        result = subprocess.run(["where", "ffmpeg"], capture_output=True, text=True)
        if result.returncode == 0:
            logging.info(f"Initial FFmpeg from: {result.stdout.strip().split('\n')[0]}")
        
        # Check if the full FFmpeg directory exists
        if not os.path.exists(_FULL_FFMPEG_DIR):
            logging.error(f"Full FFmpeg directory does not exist: {_FULL_FFMPEG_DIR}")
        else:
            # Ensure the full-featured FFmpeg (with drawtext / subtitles) is first on PATH
            logging.info(f"Prepending full FFmpeg path: {_FULL_FFMPEG_DIR}")
            prepend_ffmpeg_path(_FULL_FFMPEG_DIR)
            
            # Clear the filter cache to force re-detection with the new FFmpeg
            global _FFMPEG_FILTERS
            _FFMPEG_FILTERS = None
            
            # Log which FFmpeg we're using after prepending
            result = subprocess.run(["where", "ffmpeg"], capture_output=True, text=True)
            if result.returncode == 0:
                logging.info(f"FFmpeg after prepending: {result.stdout.strip().split('\n')[0]}")

        logging.info("=== ADDING MODERN WORD-LEVEL CAPTIONS (pre-existing data) ===")

        if not transcript_data or not transcript_data.get("segments"):
            raise Exception("No valid transcript data provided")

        # ------------------------------------------------------------------
        # 1. Create a temporary ASS subtitle file from the transcript.
        # ------------------------------------------------------------------
        ass_path = video_path.replace('.mp4', '_words.ass')
        _create_word_ass_file(transcript_data, ass_path)

        # ------------------------------------------------------------------
        # 2. Validate created subtitle file.
        # ------------------------------------------------------------------
        abs_video_path = os.path.abspath(video_path)
        abs_output_path = os.path.abspath(output_path)
        abs_ass_path = os.path.abspath(ass_path)

        if not os.path.exists(abs_ass_path):
            raise Exception(f"ASS file was not created: {abs_ass_path}")
        ass_size = os.path.getsize(abs_ass_path)
        if ass_size == 0:
            raise Exception(f"ASS file is empty: {abs_ass_path}")
        logging.info(f"ASS file validated: {ass_size} bytes")

        # ------------------------------------------------------------------
        # 3. Decide which FFmpeg filter to use.
        # ------------------------------------------------------------------
        supports_drawtext = _ffmpeg_supports_filter("drawtext")
        # Always try drawtext first because the subtitles filter is often missing on
        # Windows builds; if drawtext genuinely is unavailable the attempt will fail
        # quickly and we will fall back to subtitles.
        method_order = ["drawtext", "subtitles"]
        logging.info(f"Caption burn-in method preference: {method_order} (drawtext supported: {supports_drawtext})")

        # Prepare resources that are only needed for the drawtext branch once.
        caption_data_cache = None

        success = False
        for method in method_order:
            if method == "drawtext":
                # We attempt drawtext even if the earlier probe indicated it is
                # missing, because some Windows builds report incorrectly. If it
                # really fails, _burn_captions_with_drawtext will return False
                # and we will fall back to subtitles.
                logging.info("Attempting drawtext-based burn-in …")
                if caption_data_cache is None:
                    caption_data_cache = _extract_captions_from_ass(abs_ass_path)
                success = _burn_captions_with_drawtext(
                    abs_video_path, caption_data_cache, abs_output_path)
            else:  # subtitles
                logging.info("Attempting subtitles-based burn-in …")
                success = _burn_captions_with_subtitles(
                    abs_video_path, abs_ass_path, abs_output_path)

            if success:
                logging.info(f"Caption burn-in succeeded using '{method}' filter")
                break
            else:
                logging.warning(f"Caption burn-in with '{method}' filter failed – trying next fallback …")

        # ------------------------------------------------------------------
        # 4. Clean-up and final error handling.
        # ------------------------------------------------------------------
        if os.path.exists(abs_ass_path):
            try:
                os.remove(abs_ass_path)
            except OSError as e:
                logging.warning(f"Could not remove temporary file {abs_ass_path}: {e}")

        if not success:
            raise Exception("Caption burn-in failed with both 'drawtext' and 'subtitles' filters")

        logging.info("Modern word-level captions successfully added!")
        return output_path

    except Exception as e:
        error_msg = f"Caption creation failed: {e}"
        logging.error(error_msg)
        raise Exception(error_msg)

def _create_word_ass_file(result: dict, ass_path: str) -> None:
    """Create ASS subtitle file with modern, karaoke-style highlighting."""
    
    # Define ASS styles for karaoke effect
    # Default: White text, transparent outline/shadow for clean look
    # Highlight: White text with a yellow outline
    ass_content = """[Script Info]
Title: Modern Karaoke Captions
ScriptType: v4.00+
PlayResX: 1080
PlayResY: 1920

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,38,&H00FFFFFF,&H00FFFFFF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2.5,0,2,20,20,50,1
Style: Highlight,Arial,38,&H00FFFFFF,&H0000FFFF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2.5,0,2,20,20,50,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
    
    # Process words from transcript data
    for segment in result["segments"]:
        if 'words' not in segment:
            continue
            
        # Group words into lines for better display
        line_words = []
        line_start_time = None
        max_words_per_line = 5
        
        for word_data in segment['words']:
            if line_start_time is None:
                line_start_time = word_data['start']

            line_words.append(word_data)
            
            # Flush line when it's full or at the end of a segment
            if len(line_words) >= max_words_per_line:
                ass_content += _write_ass_line(line_words, line_start_time)
                line_words = []
                line_start_time = None
        
        # Write any remaining words in the last line
        if line_words:
            ass_content += _write_ass_line(line_words, line_start_time)

    # Write ASS file
    with open(ass_path, 'w', encoding='utf-8') as f:
        f.write(ass_content)
    
    logging.info(f"Created ASS file with modern captions: {ass_path}")

def _write_ass_line(words: list, start_time: float) -> str:
    """Writes a single line of karaoke-style ASS subtitles."""
    
    line_text_parts = []
    full_line = " ".join([w['text'].strip().upper() for w in words])
    end_time = words[-1]['end']
    
    # Calculate per-word karaoke timing
    for i, word_data in enumerate(words):
        duration_ms = int((word_data['end'] - word_data['start']) * 100)
        
        # Build the karaoke-timed text
        line_text_parts.append(f"{{\\k{duration_ms}}}{word_data['text'].strip().upper()}")
    
    karaoke_line = " ".join(line_text_parts)
    
    # Create a dialogue line for the whole phrase
    start_ass = _seconds_to_ass_time(start_time)
    end_ass = _seconds_to_ass_time(end_time)
    
    return f"Dialogue: 0,{start_ass},{end_ass},Highlight,,0,0,0,,{karaoke_line}\n"

def _seconds_to_ass_time(seconds: float) -> str:
    """Convert seconds to ASS time format (H:MM:SS.CC)."""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    centiseconds = int((seconds % 1) * 100)
    return f"{hours}:{minutes:02d}:{secs:02d}.{centiseconds:02d}"

def _convert_ass_to_srt(ass_path: str, srt_path: str) -> None:
    """Convert ASS file to SRT format for better Windows compatibility."""
    try:
        with open(ass_path, 'r', encoding='utf-8') as f:
            ass_content = f.read()
        
        # Extract dialogue lines
        dialogue_lines = []
        for line in ass_content.split('\n'):
            if line.startswith('Dialogue:'):
                dialogue_lines.append(line)
        
        # Convert to SRT format
        srt_content = ""
        for i, dialogue in enumerate(dialogue_lines):
            if not dialogue.strip():
                continue
                
            parts = dialogue.split(',', 9)
            if len(parts) < 10:
                continue
                
            start_time = parts[1]
            end_time = parts[2]
            text = parts[9]
            
            # Clean text - remove karaoke timing and formatting
            import re
            text = re.sub(r'\{\\k\d+\}', '', text)  # Remove karaoke timing
            text = re.sub(r'\{[^}]*\}', '', text)   # Remove other formatting
            text = text.strip()
            
            if not text:
                continue
            
            # Convert ASS time to SRT time
            srt_start = _ass_time_to_srt_time(start_time)
            srt_end = _ass_time_to_srt_time(end_time)
            
            srt_content += f"{i + 1}\n"
            srt_content += f"{srt_start} --> {srt_end}\n"
            srt_content += f"{text}\n\n"
        
        # Write SRT file
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
            
        logging.info(f"Converted ASS to SRT: {len(dialogue_lines)} captions")
        
    except Exception as e:
        logging.error(f"Error converting ASS to SRT: {e}")
        raise

def _ass_time_to_srt_time(ass_time: str) -> str:
    """Convert ASS time format to SRT time format."""
    # ASS: H:MM:SS.CC -> SRT: HH:MM:SS,mmm
    parts = ass_time.split(':')
    if len(parts) != 3:
        return "00:00:00,000"
    
    hours = int(parts[0])
    minutes = int(parts[1])
    sec_parts = parts[2].split('.')
    seconds = int(sec_parts[0])
    centiseconds = int(sec_parts[1]) if len(sec_parts) > 1 else 0
    milliseconds = centiseconds * 10
    
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

def _extract_captions_from_ass(ass_path: str) -> list:
    """Extract caption data from ASS file for use with MoviePy."""
    captions = []
    
    try:
        with open(ass_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        for line in content.split('\n'):
            if line.startswith('Dialogue:'):
                parts = line.split(',', 9)
                if len(parts) >= 10:
                    start_time = parts[1]
                    end_time = parts[2]
                    text = parts[9]
                    
                    # Clean text - remove karaoke timing and formatting
                    import re
                    text = re.sub(r'\{\\k\d+\}', '', text)  # Remove karaoke timing
                    text = re.sub(r'\{[^}]*\}', '', text)   # Remove other formatting
                    text = text.strip()
                    
                    if text:
                        # Convert ASS time to seconds
                        start_seconds = _ass_time_to_seconds(start_time)
                        end_seconds = _ass_time_to_seconds(end_time)
                        
                        captions.append({
                            'start': start_seconds,
                            'end': end_seconds,
                            'text': text
                        })
        
        logging.info(f"Extracted {len(captions)} captions from ASS file")
        return captions
        
    except Exception as e:
        logging.error(f"Error extracting captions: {e}")
        return []

def _ass_time_to_seconds(ass_time: str) -> float:
    """Convert ASS time format to seconds."""
    parts = ass_time.split(':')
    if len(parts) != 3:
        return 0.0
    
    hours = int(parts[0])
    minutes = int(parts[1])
    sec_parts = parts[2].split('.')
    seconds = int(sec_parts[0])
    centiseconds = int(sec_parts[1]) if len(sec_parts) > 1 else 0
    
    return hours * 3600 + minutes * 60 + seconds + centiseconds / 100.0

def _burn_captions_with_drawtext(video_path: str, caption_data: list, output_path: str) -> bool:
    """Burn captions onto video using FFmpeg drawtext filter - Windows-compatible approach."""
    try:
        # Build drawtext filter chain for all captions
        filter_parts = []
        
        for caption in caption_data:
            # Escape text for FFmpeg
            safe_text = caption['text'].replace("'", "'\\''").replace(":", "\\:")
            
            # Create drawtext filter for this caption
            drawtext_filter = (
                f"drawtext=text='{safe_text}'"
                f":fontfile='C\\:/Windows/Fonts/arial.ttf'"
                f":fontsize=38"
                f":fontcolor=white"
                f":borderw=2"
                f":bordercolor=black"
                f":x=(w-text_w)/2"
                f":y=h-text_h-50"
                f":enable='between(t,{caption['start']},{caption['end']})'"
            )
            filter_parts.append(drawtext_filter)
        
        # Combine all drawtext filters
        if not filter_parts:
            logging.warning("No captions to burn")
            return False

        # Create one big -vf argument by concatenating all drawtext filters.
        video_filter = ",".join(filter_parts)
        logging.info(f"Building FFmpeg command with {len(filter_parts)} caption overlays …")

        ffmpeg_cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-vf', video_filter,
            '-c:a', 'copy',
            output_path
        ]

        success, _, stderr = run_command(ffmpeg_cmd)
        if success:
            logging.info("Caption burning completed successfully with drawtext")
            return True
        else:
            logging.error(f"Drawtext FFmpeg failed: {stderr}")
            return False
    except Exception as e:
        logging.error(f"Drawtext caption burning failed: {e}")
        return False


def _burn_captions_with_subtitles(video_path: str, ass_path: str, output_path: str) -> bool:
    """Burn captions onto video using FFmpeg subtitles filter.

    This method is a more traditional approach and generally works on all
    platforms as long as the *subtitles* filter is available in the local
    FFmpeg build. It is used as a fallback when *drawtext* is not available
    or failed for any reason.
    """
    try:
        # Build FFmpeg command using subtitles filter. Ensure the subtitle
        # path is sanitised because FFmpeg filter graphs treat ':' and '\\'
        # specially on Windows.
        safe_ass_path = _sanitize_path_for_ffmpeg_filter(ass_path)

        ffmpeg_cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-vf', f"subtitles=filename='{safe_ass_path}'",
            '-c:a', 'copy',
            output_path
        ]

        success, _, stderr = run_command(ffmpeg_cmd)
        if success:
            logging.info("Caption burning completed successfully with subtitles filter")
            return True
        else:
            logging.error(f"Subtitles FFmpeg failed: {stderr}")
            return False

    except Exception as e:
        logging.error(f"Subtitles caption burning failed: {e}")
        return False

def _create_script_captions(video_path: str, script_text: str, output_path: str) -> str:
    """Create script-based captions using FFmpeg."""
    try:
        logging.info("Creating script-based captions...")
        
        # Create SRT file
        srt_path = video_path.replace('.mp4', '.srt')
        
        if not _create_srt_from_script(script_text, srt_path, video_path):
            raise Exception("Failed to create SRT file from script")
        
        # Burn captions with FFmpeg
        logging.info("Burning captions with FFmpeg...")
        
        video_dir = os.path.dirname(video_path)
        video_filename = os.path.basename(video_path)
        output_filename = os.path.basename(output_path)
        srt_filename = os.path.basename(srt_path)
        
        ffmpeg_cmd = [
            'ffmpeg',
            '-i', video_filename,
            '-vf', f"subtitles={srt_filename}:force_style='FontSize=32,Bold=1,PrimaryColour=&H00FFFF,OutlineColour=&H80000000,BorderStyle=3,Outline=3'",
            '-c:a', 'copy',
            '-y',
            output_filename
        ]
        
        # Run FFmpeg in video directory
        original_cwd = os.getcwd()
        try:
            os.chdir(video_dir)
            success, _, stderr = run_command(ffmpeg_cmd)
            
            if not success:
                raise Exception(f"FFmpeg failed: {stderr}")
                
        finally:
            os.chdir(original_cwd)
            
            # Clean up SRT file
            if os.path.exists(srt_path):
                os.remove(srt_path)
        
        logging.info("Script-based captions successfully added!")
        return output_path
        
    except Exception as e:
        error_msg = f"Script caption creation failed: {e}"
        logging.error(error_msg)
        raise Exception(error_msg)

def _create_srt_from_script(script_text: str, srt_path: str, video_path: str) -> bool:
    """Create SRT subtitle file from script text."""
    try:
        # Get video duration
        probe_cmd = ['ffprobe', '-v', 'error', '-show_entries', 
                     'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', video_path]
        success, stdout, _ = run_command(probe_cmd)
        
        if not success or not stdout:
            logging.error("Could not determine video duration")
            return False
            
        video_duration = float(stdout.strip())
        
        # Clean script and split into sentences
        import re
        clean_script = re.sub(r'\[Visual:.*?\]', '', script_text).strip()
        sentences = re.split(r'(?<=[.!?])\s+', clean_script)
        
        # Calculate timing
        words_per_second = 2.5
        
        with open(srt_path, 'w', encoding='utf-8') as f:
            current_time = 0.0
            
            for i, sentence in enumerate(sentences):
                if not sentence.strip():
                    continue
                    
                word_count = len(sentence.split())
                duration = max(word_count / words_per_second, 1.5)
                
                if current_time >= video_duration:
                    break
                    
                end_time = min(current_time + duration, video_duration)
                
                # Write SRT entry
                f.write(f"{i + 1}\n")
                f.write(f"{_format_srt_time(current_time)} --> {_format_srt_time(end_time)}\n")
                f.write(f"{sentence.strip()}\n\n")
                
                current_time = end_time
        
        logging.info(f"Created SRT file with {len(sentences)} captions")
        return True
        
    except Exception as e:
        logging.error(f"Error creating SRT from script: {e}")
        return False

def _format_srt_time(seconds: float) -> str:
    """Convert seconds to SRT time format."""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}" 